<!DOCTYPE html>
<html lang='zh-CN'>

<head>
  <meta name="generator" content="Hexo 6.3.0">
  <meta name="hexo-theme" content="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.19.0">
  <meta charset="utf-8">
  

  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://gcore.jsdelivr.net'>
  <link rel="preconnect" href="https://gcore.jsdelivr.net" crossorigin>
  <link rel='dns-prefetch' href='//unpkg.com'>

  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#f8f8f8">
  
  <title>商品评论情感判定 - S of S of S</title>

  
    <meta name="description" content="准备用户在电商平台上面发表的产品评价中包含着用户的偏好信息，所以通过用户评论，可以得到用户的情感倾向以及对产品属性的偏好。 1234567891011121314# 载入必要库import jiebaimport numpy as npimport pandas as pdimport sklearnimport matplotlibimport matplotlib.pyplot as plt">
<meta property="og:type" content="article">
<meta property="og:title" content="商品评论情感判定">
<meta property="og:url" content="https://dfj9401.github.io/2023/08/31/%E5%95%86%E5%93%81%E8%AF%84%E8%AE%BA%E6%83%85%E6%84%9F%E5%88%A4%E5%AE%9A/index.html">
<meta property="og:site_name" content="S of S of S">
<meta property="og:description" content="准备用户在电商平台上面发表的产品评价中包含着用户的偏好信息，所以通过用户评论，可以得到用户的情感倾向以及对产品属性的偏好。 1234567891011121314# 载入必要库import jiebaimport numpy as npimport pandas as pdimport sklearnimport matplotlibimport matplotlib.pyplot as plt">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-08-31T07:28:27.000Z">
<meta property="article:modified_time" content="2023-08-31T08:37:45.459Z">
<meta property="article:author" content="lub">
<meta name="twitter:card" content="summary">
  
  
  
  

  <!-- feed -->
  

  
    
<link rel="stylesheet" href="/css/main.css">

  

  

  

  


  
</head>

<body>
  




  <div class='l_body' id='start'>
    <aside class='l_left' layout='post'>
    

  

<header class="header"><div class="logo-wrap"><a class="title" href="/"><div class="main" ff="title">S of S of S</div><div class="sub normal cap">学习记录</div><div class="sub hover cap" style="opacity:0"> 碎碎念</div></a></div>

<nav class="menu dis-select"></nav>
</header>


<div class="widgets">
<widget class="widget-wrapper search"><div class="widget-body"><div class="search-wrapper" id="search"><form class="search-form"><input type="text" class="search-input" id="search-input" data-filter="/blog/" placeholder="文章搜索"><svg t="1670596976048" class="icon search-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2676" width="200" height="200"><path d="M938.2 832.6L723.8 618.1c-2.5-2.5-5.3-4.4-7.9-6.4 36.2-55.6 57.3-121.8 57.3-193.1C773.3 222.8 614.6 64 418.7 64S64 222.8 64 418.6c0 195.9 158.8 354.6 354.6 354.6 71.3 0 137.5-21.2 193.2-57.4 2 2.7 3.9 5.4 6.3 7.8L832.5 938c14.6 14.6 33.7 21.9 52.8 21.9 19.1 0 38.2-7.3 52.8-21.8 29.2-29.1 29.2-76.4 0.1-105.5M418.7 661.3C284.9 661.3 176 552.4 176 418.6 176 284.9 284.9 176 418.7 176c133.8 0 242.6 108.9 242.6 242.7 0 133.7-108.9 242.6-242.6 242.6" p-id="2677"></path></svg></form><div id="search-result"></div><div class="search-no-result">没有找到内容！</div></div></div></widget>


<widget class="widget-wrapper toc single" id="data-toc"><div class="widget-header cap dis-select"><span class="name">商品评论情感判定</span></div><div class="widget-body fs14"><div class="doc-tree active"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%86%E5%A4%87"><span class="toc-text">准备</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96"><span class="toc-text">1 数据读取</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="toc-text">1.1 读取数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E6%9F%A5%E7%9C%8B%E6%95%B0%E6%8D%AE"><span class="toc-text">1.2 查看数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-text">2 数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E5%8E%BB%E9%99%A4%E7%BC%BA%E5%A4%B1%E5%80%BC"><span class="toc-text">2.1 去除缺失值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E5%88%86%E8%AF%8D"><span class="toc-text">2.2 分词</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E6%9F%A5%E7%9C%8B%E5%85%B3%E9%94%AE%E8%AF%8D"><span class="toc-text">2.3 查看关键词</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E5%8F%AF%E8%A7%86%E5%8C%96%E5%88%86%E6%9E%90"><span class="toc-text">3 可视化分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E8%AF%84%E4%BB%B7%E6%9F%B1%E7%8A%B6%E5%9B%BE"><span class="toc-text">3.1 评价柱状图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E5%A5%BD%E8%AF%84%E4%BA%91%E5%9B%BE"><span class="toc-text">3.2 好评云图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E4%B8%AD%E8%AF%84%E4%BA%91%E5%9B%BE"><span class="toc-text">3.3 中评云图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-%E5%B7%AE%E8%AF%84%E4%BA%91%E5%9B%BE"><span class="toc-text">3.4 差评云图</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%96%87%E6%9C%AC%E5%90%91%E9%87%8F%E5%8C%96"><span class="toc-text">4 文本向量化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E9%AB%98%E6%96%AF%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A8%A1%E5%9E%8B"><span class="toc-text">5 高斯朴素贝叶斯模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%92%E5%88%86"><span class="toc-text">5.1 数据集划分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E6%9E%84%E5%BB%BA%E9%AB%98%E6%96%AF%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A8%A1%E5%9E%8B"><span class="toc-text">5.2 构建高斯朴素贝叶斯模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-%E9%AB%98%E6%96%AF%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0"><span class="toc-text">5.3 高斯朴素贝叶斯模型评估</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-SVM%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA"><span class="toc-text">6 SVM模型构建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-%E6%9E%84%E5%BB%BASVM%E6%A8%A1%E5%9E%8B"><span class="toc-text">6.1 构建SVM模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0"><span class="toc-text">6.2 模型评估</span></a></li></ol></li></ol></div></div></widget>




</div>


    </aside>
    <div class='l_main'>
      

      



<div class="bread-nav fs12"><div id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a><span class="sep"></span><a class="cap breadcrumb" href="/">文章</a></div><div id="post-meta">发布于&nbsp;<time datetime="2023-08-31T07:28:27.000Z">2023-08-31</time></div></div>

<article class='md-text content post'>
<h1 class="article-title"><span>商品评论情感判定</span></h1>
<h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>用户在电商平台上面发表的产品评价中包含着用户的偏好信息，所以通过用户评论，可以得到用户的情感倾向以及对产品属性的偏好。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 载入必要库</span></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> pyecharts.options <span class="keyword">as</span> opts</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> WordCloud</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Bar</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="comment">#logging</span></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="1-数据读取"><a href="#1-数据读取" class="headerlink" title="1 数据读取"></a>1 数据读取</h2><h3 id="1-1-读取数据"><a href="#1-1-读取数据" class="headerlink" title="1.1 读取数据"></a>1.1 读取数据</h3><p>某款手机的商品评论信息数据集，包含2个字段，共计8186个样本。数据集描述如下：</p>
<table>
<thead>
<tr>
<th>列名</th>
<th>说明</th>
<th>类型</th>
</tr>
</thead>
<tbody><tr>
<td><center>Comment</td>
<td>对该款手机的评论</td>
<td><center>String</td>
</tr>
<tr>
<td><center>Class</td>
<td>该评论的情感倾向: <br><left>-1 —— 差评 <br>  0 —— 中评 <br>1 —— 好评</td>
<td><center>Int</td>
</tr>
<tr>
<td>使用<code>Pandas</code>库中<code>read_csv()</code>函数读取数据。</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#读入数据集</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;./dataset/data.csv&#x27;</span>)</span><br><span class="line">data.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>

<h3 id="1-2-查看数据"><a href="#1-2-查看数据" class="headerlink" title="1.2 查看数据"></a>1.2 查看数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据集的大小</span></span><br><span class="line">data.shape</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据集的基本信息</span></span><br><span class="line">data.info()</span><br></pre></td></tr></table></figure>

<h2 id="2-数据预处理"><a href="#2-数据预处理" class="headerlink" title="2 数据预处理"></a>2 数据预处理</h2><p>使用分词库<code>jieba</code>中的<code>cut()</code>函数对文本进行分词。</p>
<h3 id="2-1-去除缺失值"><a href="#2-1-去除缺失值" class="headerlink" title="2.1 去除缺失值"></a>2.1 去除缺失值</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 移除含有缺失值的行</span></span><br><span class="line">data.dropna(axis=<span class="number">0</span>,inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看去除缺失值后的行和列</span></span><br><span class="line">data.shape</span><br></pre></td></tr></table></figure>

<h3 id="2-2-分词"><a href="#2-2-分词" class="headerlink" title="2.2 分词"></a>2.2 分词</h3><p>去除标点数字字母后再分词。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">remove_url</span>(<span class="params">src</span>):</span><br><span class="line">    <span class="comment"># 去除标点符号、数字、字母</span></span><br><span class="line">    vTEXT = re.sub(<span class="string">&#x27;[a-zA-Z0-9’!&quot;#$%&amp;\&#x27;()*+,-./:;&lt;=&gt;?@，。?★、…【】╮ ￣ ▽ ￣ ╭\\～⊙％；①（）：《》？“”‘’！[\\]^_`&#123;|&#125;~\s]+&#x27;</span>, <span class="string">&quot;&quot;</span>, src)</span><br><span class="line">    <span class="keyword">return</span> vTEXT</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cutted = []</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> data.values:</span><br><span class="line">        text = remove_url(<span class="built_in">str</span>(row[<span class="number">0</span>])) <span class="comment">#去除文本中的标点符号、数字、字母</span></span><br><span class="line">        raw_words = (<span class="string">&#x27; &#x27;</span>.join(jieba.cut(text)))<span class="comment">#分词,并用空格进行分隔</span></span><br><span class="line">        cutted.append(raw_words)</span><br><span class="line"></span><br><span class="line">cutted_array = np.array(cutted)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成新数据文件，Comment字段为分词后的内容</span></span><br><span class="line">data_cutted = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;Comment&#x27;</span>: cutted_array,</span><br><span class="line">    <span class="string">&#x27;Class&#x27;</span>: data[<span class="string">&#x27;Class&#x27;</span>]</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看分词后的数据集</span></span><br><span class="line">data_cutted.head()</span><br></pre></td></tr></table></figure>
<p><code>data_cutted</code>为进行分词之后的数据集。</p>
<h3 id="2-3-查看关键词"><a href="#2-3-查看关键词" class="headerlink" title="2.3 查看关键词"></a>2.3 查看关键词</h3><p>读取停用词文件，再用<code>jieba.analyse</code>中的<code>set_stop_words</code>函数设置停用词，使用<code>extract_tags</code>函数提取关键词。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./dataset/stopwords.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:<span class="comment">#读停用词表</span></span><br><span class="line">    stopwords = [item.strip() <span class="keyword">for</span> item <span class="keyword">in</span> f] <span class="comment">#通过列表推导式的方式获取所有停用词</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> stopwords[:<span class="number">100</span>]:<span class="comment">#读前100个停用词</span></span><br><span class="line">    <span class="built_in">print</span>(i,end=<span class="string">&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#设定停用词文件,在统计关键词的时候，过滤停用词</span></span><br><span class="line"><span class="keyword">import</span> jieba.analyse</span><br><span class="line">jieba.analyse.set_stop_words(<span class="string">&#x27;./dataset/stopwords.txt&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_cutted[<span class="string">&#x27;Comment&#x27;</span>][data_cutted[<span class="string">&#x27;Class&#x27;</span>] == <span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 好评关键词</span></span><br><span class="line">keywords_pos = jieba.analyse.extract_tags(<span class="string">&#x27;&#x27;</span>.join(data_cutted[<span class="string">&#x27;Comment&#x27;</span>][data_cutted[<span class="string">&#x27;Class&#x27;</span>] == <span class="number">1</span>]),withWeight = <span class="literal">True</span>,topK=<span class="number">30</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> keywords_pos:</span><br><span class="line">    <span class="built_in">print</span>(item[<span class="number">0</span>],end=<span class="string">&#x27; &#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#中评关键词</span></span><br><span class="line">keywords_med = jieba.analyse.extract_tags(<span class="string">&#x27;&#x27;</span>.join(data_cutted[<span class="string">&#x27;Comment&#x27;</span>][data_cutted[<span class="string">&#x27;Class&#x27;</span>] == <span class="number">0</span>]),withWeight = <span class="literal">True</span>,topK=<span class="number">30</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> keywords_med:</span><br><span class="line">    <span class="built_in">print</span>(item[<span class="number">0</span>],end=<span class="string">&#x27; &#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#差评关键词</span></span><br><span class="line">keywords_neg = jieba.analyse.extract_tags(<span class="string">&#x27;&#x27;</span>.join(data_cutted[<span class="string">&#x27;Comment&#x27;</span>][data_cutted[<span class="string">&#x27;Class&#x27;</span>] == -<span class="number">1</span>]),withWeight = <span class="literal">True</span>,topK=<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> keywords_neg:</span><br><span class="line">    <span class="built_in">print</span> (item[<span class="number">0</span>],end=<span class="string">&#x27; &#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="3-可视化分析"><a href="#3-可视化分析" class="headerlink" title="3 可视化分析"></a>3 可视化分析</h2><p>使用Pyecharts进行绘图。</p>
<h3 id="3-1-评价柱状图"><a href="#3-1-评价柱状图" class="headerlink" title="3.1 评价柱状图"></a>3.1 评价柱状图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_cutted[<span class="string">&#x27;Class&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不同类别数据记录的统计</span></span><br><span class="line">x_label = [<span class="string">&#x27;好评&#x27;</span>,<span class="string">&#x27;差评&#x27;</span>,<span class="string">&#x27;中评&#x27;</span>]</span><br><span class="line">class_num = (</span><br><span class="line">    Bar()</span><br><span class="line">    <span class="comment">#设置x轴的值</span></span><br><span class="line">    .add_xaxis(x_label) </span><br><span class="line">    <span class="comment">#设置y轴数据</span></span><br><span class="line">    .add_yaxis(<span class="string">&quot;&quot;</span>,data_cutted[<span class="string">&#x27;Class&#x27;</span>].value_counts().to_list(),color=[<span class="string">&#x27;#4c8dae&#x27;</span>])</span><br><span class="line">    <span class="comment">#设置title</span></span><br><span class="line">    .set_global_opts(title_opts=opts.TitleOpts(title=<span class="string">&quot;好评、中评、差评数量柱状图&quot;</span>))</span><br><span class="line">)</span><br><span class="line">class_num.render_notebook()</span><br></pre></td></tr></table></figure>

<h3 id="3-2-好评云图"><a href="#3-2-好评云图" class="headerlink" title="3.2 好评云图"></a>3.2 好评云图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">wordcloud_pos = (</span><br><span class="line">        WordCloud()</span><br><span class="line">        <span class="comment">#data_pair：要绘制词云图的数据</span></span><br><span class="line">        .add(series_name=<span class="string">&quot;&quot;</span>, data_pair=keywords_pos[:], word_size_range=[<span class="number">10</span>, <span class="number">66</span>])</span><br><span class="line">        .set_global_opts(</span><br><span class="line">            title_opts=opts.TitleOpts(</span><br><span class="line">                <span class="comment">#设置词云图标题和标题字号</span></span><br><span class="line">                title=<span class="string">&quot;好评关键词词云图&quot;</span>, title_textstyle_opts=opts.TextStyleOpts(font_size=<span class="number">23</span>)</span><br><span class="line">            ),</span><br><span class="line">            tooltip_opts=opts.TooltipOpts(is_show=<span class="literal">True</span>))     </span><br><span class="line">)</span><br><span class="line">wordcloud_pos.render_notebook()</span><br></pre></td></tr></table></figure>

<h3 id="3-3-中评云图"><a href="#3-3-中评云图" class="headerlink" title="3.3 中评云图"></a>3.3 中评云图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">wordcloud_med = (</span><br><span class="line">        WordCloud()</span><br><span class="line">        <span class="comment">#data_pair：要绘制词云图的数据</span></span><br><span class="line">        .add(series_name=<span class="string">&quot;&quot;</span>, data_pair=keywords_med[:], word_size_range=[<span class="number">10</span>, <span class="number">66</span>])</span><br><span class="line">        .set_global_opts(</span><br><span class="line">            title_opts=opts.TitleOpts(</span><br><span class="line">            <span class="comment">#设置词云图标题和标题字号</span></span><br><span class="line">            title=<span class="string">&quot;中评关键词词云图&quot;</span>, title_textstyle_opts=opts.TextStyleOpts(font_size=<span class="number">23</span>)</span><br><span class="line">            ),</span><br><span class="line">            tooltip_opts=opts.TooltipOpts(is_show=<span class="literal">True</span>))     </span><br><span class="line">)</span><br><span class="line">wordcloud_med.render_notebook()</span><br></pre></td></tr></table></figure>

<h3 id="3-4-差评云图"><a href="#3-4-差评云图" class="headerlink" title="3.4 差评云图"></a>3.4 差评云图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">wordcloud_neg = (</span><br><span class="line">        WordCloud()</span><br><span class="line">        <span class="comment">#data_pair：要绘制词云图的数据</span></span><br><span class="line">        .add(series_name=<span class="string">&quot;&quot;</span>, data_pair=keywords_neg[:], word_size_range=[<span class="number">10</span>, <span class="number">66</span>])</span><br><span class="line">        .set_global_opts(</span><br><span class="line">            title_opts=opts.TitleOpts(</span><br><span class="line">                <span class="comment">#设置词云图标题和标题字号</span></span><br><span class="line">                title=<span class="string">&quot;差评关键词词云图&quot;</span>, title_textstyle_opts=opts.TextStyleOpts(font_size=<span class="number">23</span>)</span><br><span class="line">            ),</span><br><span class="line">            tooltip_opts=opts.TooltipOpts(is_show=<span class="literal">True</span>))     </span><br><span class="line">)</span><br><span class="line">wordcloud_neg.render_notebook()</span><br></pre></td></tr></table></figure>
<h2 id="4-文本向量化"><a href="#4-文本向量化" class="headerlink" title="4 文本向量化"></a>4 文本向量化</h2><p>经过分词之后的文本数据集要先进行向量化之后才能输入到分类模型中进行运算。<code>TF-IDF</code>算法是常用的文本向量化算法。</p>
<p><code>TF-IDF</code>是<code>Term Frequency-Inverse Document Frequency</code>的缩写，即“词频-逆文本频率”。它由两部分组成，<code>TF</code>和<code>IDF</code>。<code>TF-IDF</code>是一种统计方法，用以评估一个词对于一个文件集或一个语料库中的一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。<br>使用<code>sklearn</code>库中的<code>TfidfVectorizer</code>实现<code>tf-idf</code>文本向量化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现向量化方法</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"></span><br><span class="line">vectorizer = TfidfVectorizer(stop_words = stopwords,max_df=<span class="number">2000</span>,min_df=<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#将文本向量化后的数据赋给data_transform</span></span><br><span class="line">data_transform = vectorizer.fit_transform(data_cutted[<span class="string">&#x27;Comment&#x27;</span>].values.tolist())</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#文本的词汇表</span></span><br><span class="line">vectorizer.get_feature_names()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#调用toarray()方法查看文本向量化后的数据</span></span><br><span class="line">data_transform.toarray()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_transform.shape</span><br></pre></td></tr></table></figure>

<h2 id="5-高斯朴素贝叶斯模型"><a href="#5-高斯朴素贝叶斯模型" class="headerlink" title="5 高斯朴素贝叶斯模型"></a>5 高斯朴素贝叶斯模型</h2><h3 id="5-1-数据集划分"><a href="#5-1-数据集划分" class="headerlink" title="5.1 数据集划分"></a>5.1 数据集划分</h3><p>使用<code>sklearn.model_selection</code>模块的<code>train_test_split()</code>函数划分训练集和测试集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split <span class="comment">#数据集划分</span></span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(data_transform, data_cutted[<span class="string">&#x27;Class&#x27;</span>],  random_state=<span class="number">10</span>,test_size=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>

<h3 id="5-2-构建高斯朴素贝叶斯模型"><a href="#5-2-构建高斯朴素贝叶斯模型" class="headerlink" title="5.2 构建高斯朴素贝叶斯模型"></a>5.2 构建高斯朴素贝叶斯模型</h3><p>从<code>sklearn.naive_bayes</code>中导入<code>GaussianNB</code>类，使用<code>GaussianNB</code>类初始化一个模型对象，命名为<code>gnb</code>，对<code>gnb</code>调用<code>fit</code>方法，带入训练集X_train，y_train进行训练。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gnb = GaussianNB()</span><br><span class="line">gnb_model = gnb.fit(X_train.toarray(),y_train)</span><br></pre></td></tr></table></figure>

<h3 id="5-3-高斯朴素贝叶斯模型评估"><a href="#5-3-高斯朴素贝叶斯模型评估" class="headerlink" title="5.3 高斯朴素贝叶斯模型评估"></a>5.3 高斯朴素贝叶斯模型评估</h3><p>从<code>sklearn.metrics</code>中导入<code>classification_report</code>分类报告用于模型评估.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gnb_prelabel = gnb_model.predict(X_test.toarray())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(classification_report(y_true=y_test,y_pred=gnb_prelabel))</span><br></pre></td></tr></table></figure>

<h2 id="6-SVM模型构建"><a href="#6-SVM模型构建" class="headerlink" title="6 SVM模型构建"></a>6 SVM模型构建</h2><h3 id="6-1-构建SVM模型"><a href="#6-1-构建SVM模型" class="headerlink" title="6.1 构建SVM模型"></a>6.1 构建SVM模型</h3><p>从<code>sklearn.svm</code>中导入<code>SVC</code>类，使用<code>SVC</code>类初始化一个模型对象，命名为<code>svc</code>，对<code>svc</code>调用<code>fit</code>方法，带入训练集X_train，y_train进行训练。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置kernel为‘rbf’高斯核，C=1</span></span><br><span class="line">svc = SVC(kernel=<span class="string">&#x27;rbf&#x27;</span>, C=<span class="number">1</span>)</span><br><span class="line">svc_model = svc.fit(X_train,y_train) </span><br></pre></td></tr></table></figure>
<p>训练模型后，可以使用模型在测试集X_test上作出预测。</p>
<h3 id="6-2-模型评估"><a href="#6-2-模型评估" class="headerlink" title="6.2 模型评估"></a>6.2 模型评估</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">svc_prelabel = svc_model.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_true=y_test,y_pred=svc_prelabel))</span><br></pre></td></tr></table></figure>
<p>通过将SVM模型与构建的高斯朴素贝叶斯模型分类结果比较，可以看出SVM在分类的精确率、召回率，以及模型的准确率上都优于高斯朴素贝叶斯模型。</p>



<div class="article-footer reveal fs14"><section id="license"><div class="header"><span>许可协议</span></div><div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p>
</div></section></div>

</article>

<div class="related-wrap reveal" id="read-next"><section class="body"><div class="item" id="prev"><div class="note">较新文章</div><a href="/2023/08/31/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%88%86%E6%9E%90/">随机森林分析</a></div><div class="item" id="next"><div class="note">较早文章</div><a href="/2023/08/31/%E6%B1%BD%E8%BD%A6%E4%BA%A7%E5%93%81%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/">汽车产品聚类分析</a></div></section></div>








      
<footer class="page-footer reveal fs12"><hr><div class="text"><p>本站由 <a href="/">@anonymity</a> 使用 <a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar">Stellar</a> 主题创建。<br>本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处。</p>
</div></footer>

      <div class='float-panel mobile-only blur' style='display:none'>
  <button type='button' class='sidebar-toggle mobile' onclick='sidebar.toggle()'>
    <svg class="icon" style="width: 1em; height: 1em;vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="15301"><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 2.3 26.8 24.6 47.5 51.6 47.6h416.5v4z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15302"></path><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 1.9 27.7 23.9 49.7 51.6 51.6h416.5z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15303"></path></svg>
  </button>
</div>

    </div>
  </div>
  <div class='scripts'>
    <script type="text/javascript">
  const stellar = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    loadCSS: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    // 从 butterfly 和 volantis 获得灵感
    loadScript: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      if (src.startsWith('/')){
        src = stellar.config.root + src.substring(1);
      }
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    // https://github.com/jerryc127/hexo-theme-butterfly
    jQuery: (fn) => {
      if (typeof jQuery === 'undefined') {
        stellar.loadScript(stellar.plugins.jQuery).then(fn)
      } else {
        fn()
      }
    }
  };
  stellar.version = '1.19.0';
  stellar.github = 'https://github.com/xaoxuu/hexo-theme-stellar/tree/1.19.0';
  stellar.config = {
    date_suffix: {
      just: '刚刚',
      min: '分钟前',
      hour: '小时前',
      day: '天前',
      month: '个月前',
    },
    root : '/',
  };

  // required plugins (only load if needs)
  stellar.plugins = {
    jQuery: 'https://gcore.jsdelivr.net/npm/jquery@3.6.2/dist/jquery.min.js'
  };

  if ('local_search') {
    stellar.search = {};
    stellar.search.service = 'local_search';
    if (stellar.search.service == 'local_search') {
      let service_obj = Object.assign({}, {"field":"all","path":"/search.json","content":true,"codeblock":true,"sort":"-date"});
      stellar.search[stellar.search.service] = service_obj;
    }
  }

  // stellar js
  stellar.plugins.stellar = Object.assign({"sites":"/js/plugins/sites.js","friends":"/js/plugins/friends.js","ghinfo":"/js/plugins/ghinfo.js","timeline":"/js/plugins/timeline.js","linkcard":"/js/plugins/linkcard.js","fcircle":"/js/plugins/fcircle.js","weibo":"/js/plugins/weibo.js"});

  stellar.plugins.marked = Object.assign("https://cdn.bootcdn.net/ajax/libs/marked/4.0.18/marked.min.js");
  // optional plugins
  if ('true' == 'true') {
    stellar.plugins.lazyload = Object.assign({"enable":true,"js":"https://gcore.jsdelivr.net/npm/vanilla-lazyload@17.8.3/dist/lazyload.min.js","transition":"blur"});
  }
  if ('true' == 'true') {
    stellar.plugins.swiper = Object.assign({"enable":true,"css":"https://unpkg.com/swiper@8.4.5/swiper-bundle.min.css","js":"https://unpkg.com/swiper@8.4.5/swiper-bundle.min.js"});
  }
  if ('' == 'true') {
    stellar.plugins.scrollreveal = Object.assign({"enable":null,"js":"https://gcore.jsdelivr.net/npm/scrollreveal@4.0.9/dist/scrollreveal.min.js","distance":"8px","duration":500,"interval":100,"scale":1});
  }
  if ('true' == 'true') {
    stellar.plugins.preload = Object.assign({"enable":true,"service":"flying_pages","instant_page":"https://gcore.jsdelivr.net/gh/volantis-x/cdn-volantis@4.1.2/js/instant_page.js","flying_pages":"https://gcore.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"});
  }
  if ('true' == 'true') {
    stellar.plugins.fancybox = Object.assign({"enable":true,"js":"https://gcore.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.umd.js","css":"https://gcore.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.css","selector":".swiper-slide img"});
  }
  if ('false' == 'true') {
    stellar.plugins.heti = Object.assign({"enable":false,"css":"https://unpkg.com/heti@0.9.2/umd/heti.min.css","js":"https://unpkg.com/heti@0.9.2/umd/heti-addon.min.js"});
  }
  if ('true' == 'true') {
    stellar.plugins.copycode = Object.assign({"enable":true,"js":"/js/plugins/copycode.js","default_text":"Copy","success_text":"Copied"});
  }
</script>

<!-- required -->

  
<script src="/js/main.js" async></script>



<!-- optional -->



<!-- inject -->


  </div>
</body>
</html>
