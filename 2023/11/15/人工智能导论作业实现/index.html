<!DOCTYPE html>
<html lang='zh-CN'>

<head>
  <meta name="generator" content="Hexo 6.3.0">
  <meta name="hexo-theme" content="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.19.0">
  <meta charset="utf-8">
  

  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://gcore.jsdelivr.net'>
  <link rel="preconnect" href="https://gcore.jsdelivr.net" crossorigin>
  <link rel='dns-prefetch' href='//unpkg.com'>

  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#f8f8f8">
  
  <title>人工智能导论作业实现 - S of S of S</title>

  
    <meta name="description" content="简单CNN实现MNIST分类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import torchimport torch.nn">
<meta property="og:type" content="article">
<meta property="og:title" content="人工智能导论作业实现">
<meta property="og:url" content="https://dfj9401.github.io/2023/11/15/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA%E4%BD%9C%E4%B8%9A%E5%AE%9E%E7%8E%B0/index.html">
<meta property="og:site_name" content="S of S of S">
<meta property="og:description" content="简单CNN实现MNIST分类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import torchimport torch.nn">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-11-15T08:45:29.000Z">
<meta property="article:modified_time" content="2023-11-15T08:50:01.766Z">
<meta property="article:author" content="lub">
<meta name="twitter:card" content="summary">
  
  
  
  

  <!-- feed -->
  

  
    
<link rel="stylesheet" href="/css/main.css">

  

  

  

  


  
</head>

<body>
  




  <div class='l_body' id='start'>
    <aside class='l_left' layout='post'>
    

  

<header class="header"><div class="logo-wrap"><a class="title" href="/"><div class="main" ff="title">S of S of S</div><div class="sub normal cap">学习记录</div><div class="sub hover cap" style="opacity:0"> 碎碎念</div></a></div>

<nav class="menu dis-select"></nav>
</header>


<div class="widgets">
<widget class="widget-wrapper search"><div class="widget-body"><div class="search-wrapper" id="search"><form class="search-form"><input type="text" class="search-input" id="search-input" data-filter="/blog/" placeholder="文章搜索"><svg t="1670596976048" class="icon search-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2676" width="200" height="200"><path d="M938.2 832.6L723.8 618.1c-2.5-2.5-5.3-4.4-7.9-6.4 36.2-55.6 57.3-121.8 57.3-193.1C773.3 222.8 614.6 64 418.7 64S64 222.8 64 418.6c0 195.9 158.8 354.6 354.6 354.6 71.3 0 137.5-21.2 193.2-57.4 2 2.7 3.9 5.4 6.3 7.8L832.5 938c14.6 14.6 33.7 21.9 52.8 21.9 19.1 0 38.2-7.3 52.8-21.8 29.2-29.1 29.2-76.4 0.1-105.5M418.7 661.3C284.9 661.3 176 552.4 176 418.6 176 284.9 284.9 176 418.7 176c133.8 0 242.6 108.9 242.6 242.7 0 133.7-108.9 242.6-242.6 242.6" p-id="2677"></path></svg></form><div id="search-result"></div><div class="search-no-result">没有找到内容！</div></div></div></widget>


<widget class="widget-wrapper toc single" id="data-toc"><div class="widget-header cap dis-select"><span class="name">人工智能导论作业实现</span></div><div class="widget-body fs14"><div class="doc-tree active"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%80%E5%8D%95CNN%E5%AE%9E%E7%8E%B0MNIST%E5%88%86%E7%B1%BB"><span class="toc-text">简单CNN实现MNIST分类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%8A%A8%E6%80%81%E8%87%AA%E9%80%82%E5%BA%94%E5%8D%B7%E7%A7%AF%E5%AE%9E%E7%8E%B0MNIST%E5%88%86%E7%B1%BB"><span class="toc-text">使用动态自适应卷积实现MNIST分类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E7%9A%84%E5%8A%A8%E6%80%81%E5%8D%B7%E7%A7%AF%E6%A8%A1%E5%9D%97"><span class="toc-text">使用的动态卷积模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E5%8D%B7%E7%A7%AF%E4%BD%BF%E7%94%A8%E7%9A%84%E6%9D%83%E9%87%8D%E8%AE%A1%E7%AE%97%E5%87%BD%E6%95%B0"><span class="toc-text">动态卷积使用的权重计算函数</span></a></li></ol></li></ol></div></div></widget>




</div>


    </aside>
    <div class='l_main'>
      

      



<div class="bread-nav fs12"><div id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a><span class="sep"></span><a class="cap breadcrumb" href="/">文章</a></div><div id="post-meta">发布于&nbsp;<time datetime="2023-11-15T08:45:29.000Z">2023-11-15</time></div></div>

<article class='md-text content post'>
<h1 class="article-title"><span>人工智能导论作业实现</span></h1>
<h2 id="简单CNN实现MNIST分类"><a href="#简单CNN实现MNIST分类" class="headerlink" title="简单CNN实现MNIST分类"></a>简单CNN实现MNIST分类</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个使用普通CNN的模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CNNNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(CNNNet, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=<span class="number">1</span>, out_channels=<span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(in_channels=<span class="number">16</span>, out_channels=<span class="number">32</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.fc = nn.Linear(<span class="number">32</span> * <span class="number">7</span> * <span class="number">7</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = nn.ReLU()(x)</span><br><span class="line">        x = nn.MaxPool2d(kernel_size=<span class="number">2</span>)(x)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = nn.ReLU()(x)</span><br><span class="line">        x = nn.MaxPool2d(kernel_size=<span class="number">2</span>)(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置随机种子</span></span><br><span class="line">torch.manual_seed(<span class="number">40</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义训练和测试数据的转换</span></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载MNIST数据集</span></span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义数据加载器</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个CNNNet实例</span></span><br><span class="line">model = CNNNet()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数和优化器</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model, train_loader, criterion, optimizer, epochs</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        running_loss = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            output = model(data)</span><br><span class="line">            loss = criterion(output, target)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            running_loss += loss.item()</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> batch_idx % <span class="number">100</span> == <span class="number">99</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;[Epoch: %d, Batch: %5d] Loss: %.3f&#x27;</span> % (epoch+<span class="number">1</span>, batch_idx+<span class="number">1</span>, running_loss/<span class="number">100</span>))</span><br><span class="line">                running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在训练集上训练模型</span></span><br><span class="line">train(model, train_loader, criterion, optimizer, epochs=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在测试集上评估模型性能</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">model, test_loader</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">            output = model(data)</span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(output.data, <span class="number">1</span>)</span><br><span class="line">            total += target.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == target).<span class="built_in">sum</span>().item()</span><br><span class="line">    accuracy = <span class="number">100</span> * correct / total</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accuracy on test set: %.2f%%&#x27;</span> % accuracy)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在测试集上测试模型性能</span></span><br><span class="line">test(model, test_loader)</span><br></pre></td></tr></table></figure>

<h2 id="使用动态自适应卷积实现MNIST分类"><a href="#使用动态自适应卷积实现MNIST分类" class="headerlink" title="使用动态自适应卷积实现MNIST分类"></a>使用动态自适应卷积实现MNIST分类</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"><span class="keyword">from</span> pac <span class="keyword">import</span> PacConv2d</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个使用PacConv的CNN模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PacConvNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(PacConvNet, self).__init__()</span><br><span class="line">        self.pacconv1 = PacConv2d(in_channels=<span class="number">1</span>, out_channels=<span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.pacconv2 = PacConv2d(in_channels=<span class="number">16</span>, out_channels=<span class="number">32</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.fc = nn.Linear(<span class="number">25088</span>, <span class="number">1568</span>)  <span class="comment"># 修改线性层的输入维度</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, input_for_kernel</span>):</span><br><span class="line">        x = self.pacconv1(x, input_for_kernel)</span><br><span class="line">        x = nn.ReLU()(x)</span><br><span class="line">        x = self.pacconv2(x, input_for_kernel)</span><br><span class="line">        x = nn.ReLU()(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置随机种子</span></span><br><span class="line">torch.manual_seed(<span class="number">40</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义训练和测试数据的转换</span></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载MNIST数据集</span></span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义数据加载器</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个PacConvNet实例</span></span><br><span class="line">model = PacConvNet()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数和优化器</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model, train_loader, criterion, optimizer, epochs</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        running_loss = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            output = model(data, data)  <span class="comment"># 提供input_for_kernel参数</span></span><br><span class="line">            loss = criterion(output, target)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            running_loss += loss.item()</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> batch_idx % <span class="number">100</span> == <span class="number">99</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;[Epoch: %d, Batch: %5d] Loss: %.3f&#x27;</span> % (epoch+<span class="number">1</span>, batch_idx+<span class="number">1</span>, running_loss/<span class="number">100</span>))</span><br><span class="line">                running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在训练集上训练模型</span></span><br><span class="line">train(model, train_loader, criterion, optimizer, epochs=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在测试集上评估模型性能</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">model, test_loader</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">            output = model(data, data)  <span class="comment"># 提供input_for_kernel参数</span></span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(output.data, <span class="number">1</span>)</span><br><span class="line">            total += target.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == target).<span class="built_in">sum</span>().item()</span><br><span class="line">    accuracy = <span class="number">100</span> * correct / total</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accuracy on test set: %.2f%%&#x27;</span> % accuracy)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在测试集上测试模型性能</span></span><br><span class="line">test(model, test_loader)</span><br></pre></td></tr></table></figure>
<h3 id="使用的动态卷积模块"><a href="#使用的动态卷积模块" class="headerlink" title="使用的动态卷积模块"></a>使用的动态卷积模块</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PacConv2d</span>(<span class="title class_ inherited__">_PacConvNd</span>):</span><br><span class="line">    <span class="string">r&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Args (in addition to those of Conv2d):</span></span><br><span class="line"><span class="string">        kernel_type (str): &#x27;gaussian&#x27; | &#x27;inv_&#123;alpha&#125;_&#123;lambda&#125;[_asym][_fixed]&#x27;. Default: &#x27;gaussian&#x27;</span></span><br><span class="line"><span class="string">        smooth_kernel_type (str): &#x27;none&#x27; | &#x27;gaussian&#x27; | &#x27;average_&#123;sz&#125;&#x27; | &#x27;full_&#123;sz&#125;&#x27;. Default: &#x27;none&#x27;</span></span><br><span class="line"><span class="string">        normalize_kernel (bool): Default: False</span></span><br><span class="line"><span class="string">        shared_filters (bool): Default: False</span></span><br><span class="line"><span class="string">        filler (str): &#x27;uniform&#x27;. Default: &#x27;uniform&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Note:</span></span><br><span class="line"><span class="string">        - kernel_size only accepts odd numbers</span></span><br><span class="line"><span class="string">        - padding should not be larger than :math:`dilation * (kernel_size - 1) / 2`</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, kernel_size, stride=<span class="number">1</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, bias=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                 kernel_type=<span class="string">&#x27;gaussian&#x27;</span>, smooth_kernel_type=<span class="string">&#x27;none&#x27;</span>, normalize_kernel=<span class="literal">False</span>, shared_filters=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 filler=<span class="string">&#x27;uniform&#x27;</span>, native_impl=<span class="literal">False</span></span>):</span><br><span class="line">        kernel_size = _pair(kernel_size)</span><br><span class="line">        stride = _pair(stride)</span><br><span class="line">        padding = _pair(padding)</span><br><span class="line">        dilation = _pair(dilation)</span><br><span class="line">        <span class="built_in">super</span>(PacConv2d, self).__init__(</span><br><span class="line">            in_channels, out_channels, kernel_size, stride,</span><br><span class="line">            padding, dilation, <span class="literal">False</span>, _pair(<span class="number">0</span>), bias,</span><br><span class="line">            <span class="literal">False</span>, kernel_type, smooth_kernel_type, <span class="literal">False</span>, normalize_kernel, shared_filters, filler)</span><br><span class="line"></span><br><span class="line">        self.native_impl = native_impl</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compute_kernel</span>(<span class="params">self, input_for_kernel, input_mask=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="keyword">return</span> packernel2d(input_for_kernel, input_mask,</span><br><span class="line">                           kernel_size=self.kernel_size, stride=self.stride, padding=self.padding,</span><br><span class="line">                           dilation=self.dilation, kernel_type=self.kernel_type,</span><br><span class="line">                           smooth_kernel_type=self.smooth_kernel_type,</span><br><span class="line">                           smooth_kernel=self.smooth_kernel <span class="keyword">if</span> <span class="built_in">hasattr</span>(self, <span class="string">&#x27;smooth_kernel&#x27;</span>) <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">                           inv_alpha=self.inv_alpha <span class="keyword">if</span> <span class="built_in">hasattr</span>(self, <span class="string">&#x27;inv_alpha&#x27;</span>) <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">                           inv_lambda=self.inv_lambda <span class="keyword">if</span> <span class="built_in">hasattr</span>(self, <span class="string">&#x27;inv_lambda&#x27;</span>) <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">                           channel_wise=<span class="literal">False</span>, normalize_kernel=self.normalize_kernel, transposed=<span class="literal">False</span>,</span><br><span class="line">                           native_impl=self.native_impl)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input_2d, input_for_kernel, kernel=<span class="literal">None</span>, mask=<span class="literal">None</span></span>):</span><br><span class="line">        output_mask = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> kernel <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            kernel, output_mask = self.compute_kernel(input_for_kernel, mask)</span><br><span class="line"></span><br><span class="line">        output = pacconv2d(input_2d, kernel, self.weight, self.bias, self.stride, self.padding, self.dilation,</span><br><span class="line">                           self.shared_filters, self.native_impl)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output <span class="keyword">if</span> output_mask <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> (output, output_mask)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="动态卷积使用的权重计算函数"><a href="#动态卷积使用的权重计算函数" class="headerlink" title="动态卷积使用的权重计算函数"></a>动态卷积使用的权重计算函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">packernel2d</span>(<span class="params"><span class="built_in">input</span>, mask=<span class="literal">None</span>, kernel_size=<span class="number">0</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>, output_padding=<span class="number">0</span>, dilation=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                kernel_type=<span class="string">&#x27;gaussian&#x27;</span>, smooth_kernel_type=<span class="string">&#x27;none&#x27;</span>, smooth_kernel=<span class="literal">None</span>, inv_alpha=<span class="literal">None</span>, inv_lambda=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                channel_wise=<span class="literal">False</span>, normalize_kernel=<span class="literal">False</span>, transposed=<span class="literal">False</span>, native_impl=<span class="literal">False</span></span>):</span><br><span class="line">    kernel_size = _pair(kernel_size)</span><br><span class="line">    dilation = _pair(dilation)</span><br><span class="line">    padding = _pair(padding)</span><br><span class="line">    output_padding = _pair(output_padding)</span><br><span class="line">    stride = _pair(stride)</span><br><span class="line">    output_mask = <span class="literal">False</span> <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="literal">True</span></span><br><span class="line">    norm = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> mask.dtype != <span class="built_in">input</span>.dtype:</span><br><span class="line">        mask = torch.tensor(mask, dtype=<span class="built_in">input</span>.dtype, device=<span class="built_in">input</span>.device)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> transposed:</span><br><span class="line">        in_sz = <span class="built_in">tuple</span>(<span class="built_in">int</span>((o - op - <span class="number">1</span> - (k - <span class="number">1</span>) * d + <span class="number">2</span> * p) // s) + <span class="number">1</span> <span class="keyword">for</span> (o, k, s, p, op, d) <span class="keyword">in</span></span><br><span class="line">                      <span class="built_in">zip</span>(<span class="built_in">input</span>.shape[-<span class="number">2</span>:], kernel_size, stride, padding, output_padding, dilation))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        in_sz = <span class="built_in">input</span>.shape[-<span class="number">2</span>:]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">or</span> normalize_kernel:</span><br><span class="line">        mask_pattern = <span class="built_in">input</span>.new_ones(<span class="number">1</span>, <span class="number">1</span>, *in_sz)</span><br><span class="line">        mask_pattern = nd2col(mask_pattern, kernel_size, stride=stride, padding=padding, output_padding=output_padding,</span><br><span class="line">                              dilation=dilation, transposed=transposed)</span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            mask = nd2col(mask, kernel_size, stride=stride, padding=padding, output_padding=output_padding,</span><br><span class="line">                          dilation=dilation, transposed=transposed)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> normalize_kernel:</span><br><span class="line">                norm = mask.<span class="built_in">sum</span>(dim=<span class="number">2</span>, keepdim=<span class="literal">True</span>).<span class="built_in">sum</span>(dim=<span class="number">3</span>, keepdim=<span class="literal">True</span>) \</span><br><span class="line">                       / mask_pattern.<span class="built_in">sum</span>(dim=<span class="number">2</span>, keepdim=<span class="literal">True</span>).<span class="built_in">sum</span>(dim=<span class="number">3</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mask = mask_pattern</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> transposed:</span><br><span class="line">        stride = _pair(<span class="number">1</span>)</span><br><span class="line">        padding = <span class="built_in">tuple</span>((k - <span class="number">1</span>) * d // <span class="number">2</span> <span class="keyword">for</span> (k, d) <span class="keyword">in</span> <span class="built_in">zip</span>(kernel_size, dilation))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> native_impl:</span><br><span class="line">        bs, k_ch, in_h, in_w = <span class="built_in">input</span>.shape</span><br><span class="line"></span><br><span class="line">        x = nd2col(<span class="built_in">input</span>, kernel_size, stride=stride, padding=padding, dilation=dilation)</span><br><span class="line">        x = x.view(bs, k_ch, -<span class="number">1</span>, *x.shape[-<span class="number">2</span>:]).contiguous()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> smooth_kernel_type == <span class="string">&#x27;none&#x27;</span>:</span><br><span class="line">            self_idx = kernel_size[<span class="number">0</span>] * kernel_size[<span class="number">1</span>] // <span class="number">2</span></span><br><span class="line">            feat_0 = x[:, :, self_idx:self_idx + <span class="number">1</span>, :, :]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            smooth_kernel_size = smooth_kernel.shape[<span class="number">2</span>:]</span><br><span class="line">            smooth_padding = (<span class="built_in">int</span>(padding[<span class="number">0</span>] - (kernel_size[<span class="number">0</span>] - smooth_kernel_size[<span class="number">0</span>]) / <span class="number">2</span>),</span><br><span class="line">                              <span class="built_in">int</span>(padding[<span class="number">1</span>] - (kernel_size[<span class="number">1</span>] - smooth_kernel_size[<span class="number">1</span>]) / <span class="number">2</span>))</span><br><span class="line">            crop = <span class="built_in">tuple</span>(-<span class="number">1</span> * np.minimum(<span class="number">0</span>, smooth_padding))</span><br><span class="line">            input_for_kernel_crop = <span class="built_in">input</span>.view(-<span class="number">1</span>, <span class="number">1</span>, in_h, in_w)[:, :,</span><br><span class="line">                                    crop[<span class="number">0</span>]:_neg_idx(crop[<span class="number">0</span>]), crop[<span class="number">1</span>]:_neg_idx(crop[<span class="number">1</span>])]</span><br><span class="line">            smoothed = F.conv2d(input_for_kernel_crop, smooth_kernel,</span><br><span class="line">                                stride=stride, padding=<span class="built_in">tuple</span>(np.maximum(<span class="number">0</span>, smooth_padding)))</span><br><span class="line">            feat_0 = smoothed.view(bs, k_ch, <span class="number">1</span>, *x.shape[-<span class="number">2</span>:])</span><br><span class="line">        x = x - feat_0</span><br><span class="line">        <span class="keyword">if</span> kernel_type.find(<span class="string">&#x27;_asym&#x27;</span>) &gt;= <span class="number">0</span>:</span><br><span class="line">            x = F.relu(x, inplace=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># x.pow_(2)  # this causes an autograd issue in pytorch&gt;0.4</span></span><br><span class="line">        x = x * x</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> channel_wise:</span><br><span class="line">            x = torch.<span class="built_in">sum</span>(x, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">if</span> kernel_type == <span class="string">&#x27;gaussian&#x27;</span>:</span><br><span class="line">            x = torch.exp_(x.mul_(-<span class="number">0.5</span>))  <span class="comment"># TODO profiling for identifying the culprit of 5x slow down</span></span><br><span class="line">            <span class="comment"># x = torch.exp(-0.5 * x)</span></span><br><span class="line">        <span class="keyword">elif</span> kernel_type.startswith(<span class="string">&#x27;inv_&#x27;</span>):</span><br><span class="line">            epsilon = <span class="number">1e-4</span></span><br><span class="line">            x = inv_alpha.view(<span class="number">1</span>, -<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>) \</span><br><span class="line">                + torch.<span class="built_in">pow</span>(x + epsilon, <span class="number">0.5</span> * inv_lambda.view(<span class="number">1</span>, -<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError()</span><br><span class="line">        output = x.view(*(x.shape[:<span class="number">2</span>] + <span class="built_in">tuple</span>(kernel_size) + x.shape[-<span class="number">2</span>:])).contiguous()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">assert</span> (smooth_kernel_type == <span class="string">&#x27;none&#x27;</span> <span class="keyword">and</span></span><br><span class="line">                kernel_type == <span class="string">&#x27;gaussian&#x27;</span>)</span><br><span class="line">        output = GaussKernel2dFn.apply(<span class="built_in">input</span>, kernel_size, stride, padding, dilation, channel_wise)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        output = output * mask  <span class="comment"># avoid numerical issue on masked positions</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> normalize_kernel:</span><br><span class="line">        norm = output.<span class="built_in">sum</span>(dim=<span class="number">2</span>, keepdim=<span class="literal">True</span>).<span class="built_in">sum</span>(dim=<span class="number">3</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> norm <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        empty_mask = (norm == <span class="number">0</span>)</span><br><span class="line">        output = output / (norm + torch.tensor(empty_mask, dtype=<span class="built_in">input</span>.dtype, device=<span class="built_in">input</span>.device))</span><br><span class="line">        output_mask = (<span class="number">1</span> - empty_mask) <span class="keyword">if</span> output_mask <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        output_mask = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output, output_mask</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<div class="article-footer reveal fs14"><section id="license"><div class="header"><span>许可协议</span></div><div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p>
</div></section></div>

</article>

<div class="related-wrap reveal" id="read-next"><section class="body"><div class="item" id="prev"></div><div class="item" id="next"><div class="note">较早文章</div><a href="/2023/11/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BD%9C%E4%B8%9A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E9%83%A8%E5%88%86/">机器学习作业代码实现部分</a></div></section></div>








      
<footer class="page-footer reveal fs12"><hr><div class="text"><p>本站由 <a href="/">@anonymity</a> 使用 <a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar">Stellar</a> 主题创建。<br>本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处。</p>
</div></footer>

      <div class='float-panel mobile-only blur' style='display:none'>
  <button type='button' class='sidebar-toggle mobile' onclick='sidebar.toggle()'>
    <svg class="icon" style="width: 1em; height: 1em;vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="15301"><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 2.3 26.8 24.6 47.5 51.6 47.6h416.5v4z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15302"></path><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 1.9 27.7 23.9 49.7 51.6 51.6h416.5z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15303"></path></svg>
  </button>
</div>

    </div>
  </div>
  <div class='scripts'>
    <script type="text/javascript">
  const stellar = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    loadCSS: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    // 从 butterfly 和 volantis 获得灵感
    loadScript: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      if (src.startsWith('/')){
        src = stellar.config.root + src.substring(1);
      }
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    // https://github.com/jerryc127/hexo-theme-butterfly
    jQuery: (fn) => {
      if (typeof jQuery === 'undefined') {
        stellar.loadScript(stellar.plugins.jQuery).then(fn)
      } else {
        fn()
      }
    }
  };
  stellar.version = '1.19.0';
  stellar.github = 'https://github.com/xaoxuu/hexo-theme-stellar/tree/1.19.0';
  stellar.config = {
    date_suffix: {
      just: '刚刚',
      min: '分钟前',
      hour: '小时前',
      day: '天前',
      month: '个月前',
    },
    root : '/',
  };

  // required plugins (only load if needs)
  stellar.plugins = {
    jQuery: 'https://gcore.jsdelivr.net/npm/jquery@3.6.2/dist/jquery.min.js'
  };

  if ('local_search') {
    stellar.search = {};
    stellar.search.service = 'local_search';
    if (stellar.search.service == 'local_search') {
      let service_obj = Object.assign({}, {"field":"all","path":"/search.json","content":true,"codeblock":true,"sort":"-date"});
      stellar.search[stellar.search.service] = service_obj;
    }
  }

  // stellar js
  stellar.plugins.stellar = Object.assign({"sites":"/js/plugins/sites.js","friends":"/js/plugins/friends.js","ghinfo":"/js/plugins/ghinfo.js","timeline":"/js/plugins/timeline.js","linkcard":"/js/plugins/linkcard.js","fcircle":"/js/plugins/fcircle.js","weibo":"/js/plugins/weibo.js"});

  stellar.plugins.marked = Object.assign("https://cdn.bootcdn.net/ajax/libs/marked/4.0.18/marked.min.js");
  // optional plugins
  if ('true' == 'true') {
    stellar.plugins.lazyload = Object.assign({"enable":true,"js":"https://gcore.jsdelivr.net/npm/vanilla-lazyload@17.8.3/dist/lazyload.min.js","transition":"blur"});
  }
  if ('true' == 'true') {
    stellar.plugins.swiper = Object.assign({"enable":true,"css":"https://unpkg.com/swiper@8.4.5/swiper-bundle.min.css","js":"https://unpkg.com/swiper@8.4.5/swiper-bundle.min.js"});
  }
  if ('' == 'true') {
    stellar.plugins.scrollreveal = Object.assign({"enable":null,"js":"https://gcore.jsdelivr.net/npm/scrollreveal@4.0.9/dist/scrollreveal.min.js","distance":"8px","duration":500,"interval":100,"scale":1});
  }
  if ('true' == 'true') {
    stellar.plugins.preload = Object.assign({"enable":true,"service":"flying_pages","instant_page":"https://gcore.jsdelivr.net/gh/volantis-x/cdn-volantis@4.1.2/js/instant_page.js","flying_pages":"https://gcore.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"});
  }
  if ('true' == 'true') {
    stellar.plugins.fancybox = Object.assign({"enable":true,"js":"https://gcore.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.umd.js","css":"https://gcore.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.css","selector":".swiper-slide img"});
  }
  if ('false' == 'true') {
    stellar.plugins.heti = Object.assign({"enable":false,"css":"https://unpkg.com/heti@0.9.2/umd/heti.min.css","js":"https://unpkg.com/heti@0.9.2/umd/heti-addon.min.js"});
  }
  if ('true' == 'true') {
    stellar.plugins.copycode = Object.assign({"enable":true,"js":"/js/plugins/copycode.js","default_text":"Copy","success_text":"Copied"});
  }
</script>

<!-- required -->

  
<script src="/js/main.js" async></script>



<!-- optional -->



<!-- inject -->


  </div>
</body>
</html>
