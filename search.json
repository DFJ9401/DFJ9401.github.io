[{"title":"图书数据可视化","path":"/2023/08/30/图书数据可视化/","content":"1 数据集介绍使用上次清洗过的数据进行数据分析，并利用可视化图形对分析。数据集共9个字段，600个样本，如下： 价格 星级 评论数 作者 出版日期 出版社 书名 简介1 简介2 2 数据读取2.1 导入相关的库12345678#import pandas as pdimport seaborn as snsimport matplotlib.pyplot as pltimport jiebafrom wordcloud import WordCloud,STOPWORDS# 设置中文字体plt.rcParams[&#x27;font.sans-serif&#x27;]=&#x27;SimHei&#x27;%config InlineBackend.figure_format = &#x27;svg&#x27; 2.2 数据读取调用Pandas对象的read_csv()函数。 1234#读数据集data = pd.read_csv(&#x27;./dataset/当当网机器学习图书数据（已清洗）.csv&#x27;,sep=&#x27;,&#x27;,encoding=&#x27;utf-8&#x27;)#查看前5行data.head(5) 2.3 字段基本统计信息使用DataFrame对象的describe()方法可以查看各列基本统计信息，统计并生成数据集哥哥字段的样本数、均值、标准差、最小值、四分位数等。describe()方法主要参数： percentiles：自定义分位数，默认是25%,50%,75% include：指定统计的数据类型，默认只统计数值型，当为all时数值和离散型都统计 exclude：意排除哪些字段，默认统计所有列 12#查看数据基本统计信息 data.describe(include=&#x27;all&#x27;) 3 可视化使用python中的Matplotilb、Seaborn等库进行可视化。 3.1 各出版社的图书数量统计各出版社关于机器学习相关的图书数量，对出版数量有直观了解。Series对象的value_counts()方法可以对某列的取值数量分布进行统计，其主要参数： normallize：默认为False，若为True，则以百分比的形式显示 sort：是否对结果进行排序，默认为True ascending: 默认对值降序排列(False) dropna:是否删除空值，默认删除(True) 12# 各出版社出版的图书数量data[&#x27;出版社&#x27;].value_counts(ascending=True) 从统计结果可以看到出版机器学习相关图书最多的机械工业出版社。 3.2 各星级图书数量统计柱状图使用Seaborn中的barplot函数绘制柱状图，其主要参数有： x：x坐标传入的值 y：y坐标传入的值 data：传入的数据集 12# 查看各星级的数量data[&#x27;星级&#x27;].value_counts() 123456789101112# # 绘制画布，即画布的大小和分辨率plt.figure(figsize=(8,5), dpi=100)x = data[&#x27;星级&#x27;].value_counts().indexy = data[&#x27;星级&#x27;].value_counts().valuessns.barplot(x,y)# 设置标题plt.title(&#x27;各星级图书数量统计柱状图&#x27;,fontsize=13)# 设置x轴标签plt.xlabel(&#x27;星级&#x27;,fontsize=10)# 设置y轴标签plt.ylabel(&#x27;数量&#x27;,fontsize=10)plt.show() 3.3 图书价格直方图使用Seaborn中的histplot函数来绘制直方图，主要参数有： data：传入的数据 x：做直方图所用的数据，必须是一维数组 bins：分组数量 12345678910111213# 绘制画布，即大小和分辨率plt.figure(figsize=(8,5),dpi=100)# 绘图，分别统计不同图书价格的数量sns.histplot(data,x=&#x27;价格&#x27;,bins=20)# 绘制价格均值直线plt.plot([data[&#x27;价格&#x27;].mean(),data[&#x27;价格&#x27;].mean()],[0,200],&#x27;g--&#x27;)# 设置标题plt.title(&#x27;图书价格直方图&#x27;,fontsize=13)# 设置x轴标签plt.xlabel(&#x27;图书价格&#x27;,fontsize=10)# 设置y轴标签plt.ylabel(&#x27;数量&#x27;,fontsize=10)plt.show() 3.4 高价图书分析设置价格大于100元为高价图书，筛选高价图书如下： 1234# 利用DataFrame直接筛选输出高价图书data_price_high = data[data[&#x27;价格&#x27;]&gt;100]# 查看前3行高价图书信息data_price_high.head(3) 3.4.1高价书出版社统计使用Matplotlib中的pie函数绘制饼状图，主要参数如下： x：每一块的数值比例 labels：每一块外侧显示的说明文字 autopct：控制图内显示的百分比 startangle：起始角度，默认图是从x轴正方向画起，逆时针方向 pctdistance：数值标签距离圆心的距离 radius：控制饼图半径 1data_price_high[&#x27;出版社&#x27;].value_counts().index 123456789## 按照出版社进行分段统计x = data_price_high[&#x27;出版社&#x27;].value_counts().values# 设置饼图的标签labels = data_price_high[&#x27;出版社&#x27;].value_counts().index# 绘制画布plt.figure(figsize=(8,5),dpi=100)# 绘制饼状图plt.pie(x,labels=labels,autopct=&#x27;%1.1f%%&#x27;,startangle=30,pctdistance=0.8,radius=1)plt.show() 3.4.2 高价书星级评定使用Matplotlib中的bach()函数绘制柱状图，主要参数如下： y：y坐标 width：柱子的宽度，即统计的数值大小 height：柱子的高度，默认为0.8 1data_price_high.groupby(&#x27;出版社&#x27;)[&#x27;星级&#x27;].mean() 1234567891011# 取值各个出版社星级的平均值width = data_price_high.groupby(&#x27;出版社&#x27;)[&#x27;星级&#x27;].mean().values# 按照出版社求各个出版社星级评分的平均值，取出索引，即出版社y = data_price_high.groupby(&#x27;出版社&#x27;)[&#x27;星级&#x27;].mean().index# 设置画布plt.figure(figsize=(8,5),dpi=100)# 绘图plt.barh(y,width,height=0.8,color=&#x27;orange&#x27;)plt.title(&#x27;高价图书星级评定&#x27;,fontsize=13)plt.show() 3.5 各出版社图书价格均值对各出版社出版图书价格均值进行统计。 12# 按照出版社进行分组聚合，计算每组平均的图书价格，计算结果如下data.groupby(&#x27;出版社&#x27;)[&#x27;价格&#x27;].mean().sort_values(ascending=False) 3.6 各出版社出版图书口碑分析将出版社一列分组，计算各出版社图书平均星级。 1234# 按照出版社分段统计，求各个出版社星级的均值data_star_mean = data.groupby(&#x27;出版社&#x27;)[&#x27;星级&#x27;].mean()# 将每个出版社的平均星级进行降序排序 默认是升序排序data_star_mean.sort_values(ascending = False) 3.7 图书简介文本分词对图书的简介进行分析，首先数据中简介1这一列是文本类型，因此我们要先进行分词，分词的目的是将文本按一定的规则进行分词处理。在这里我们使用jieba库里面的cut函数进行分词，jieba库是专门使用Python语言开发的分词库,占用资源较少，常识类文档的分词精度较高。cut函数的主要参数如下： sentence:要进行的分词的句子样本 cut_all:分词的模式，有全模式和精准模式，默认false，精准模式 HMM:隐马尔科夫链，即HMM模型，默认开启，这个是在分词的理论模型中用到的 1234567# 对数据集的每个样本的文本进行中文分词#记录分词后的结果cutted = [] for item in data[&#x27;简介1&#x27;].values: raw_words = (&quot; &quot;.join(jieba.cut(str(item)))) cutted.append(raw_words) 1234567# 创建一个新的DataFrame，将没分词和分词后的句子添加到里面data_cutted = pd.DataFrame(&#123; &#x27;简介1&#x27;: data[&#x27;简介1&#x27;], &#x27;简介1_cut&#x27;: cutted&#125;)data_cutted.head() 3.8 词云图分词处理完毕后，再处理停用词，最后形成词云图。利用wordcloud中的WordColoud()函数绘制词云图，其中主要参数为： font_path:字体路径 stopword:将被忽略或者是删除的单词表 width:词云图的宽度，默认400 height：词云图的高度，默认200 max_font_size:最大字体的大小 12345# 读取停用词stopwd=pd.read_csv(&#x27;./dataset/中文停用词表数据集.csv&#x27;)stopwords=set([i for i in stopwd[&#x27;cn_stopwords&#x27;]])print(len(stopwords))# stopwords 1234567# 定义词云图wc = WordCloud(font_path = &quot;./dataset/simsun.ttc&quot;,#设置字体 stopwords = stopwords, #设置停用词 background_color = &#x27;white&#x27;, width = 1000, height = 618, max_font_size = 400) 12345678# 运行统计词频wc.generate(data_cutted[&#x27;简介1_cut&#x27;].sum())# 4、显示图片plt.figure(&quot;词云图&quot;) #指定所绘图名称plt.imshow(wc) # 以图片的形式显示词云plt.axis(&quot;off&quot;) #关闭图像坐标系plt.show() 1# data_cutted[&#x27;简介1_cut&#x27;].sum() 词云图突出显示了简介中出现频率较高的词，出现词频越高的词在词云图中显示越大。"},{"title":"网站数据清洗","path":"/2023/08/30/网站数据清洗/","content":"1 数据集介绍来自某图书网站爬取的机器学习相关图书信息，数据集共600条数据，5个字段，如下 书名 出版信息 当前价格 星级 评论数 2 数据读取2.1 读取数据数据集保存在csv文件中，使用Pandas中的read_csv()读取csv文件，结果保存为DataFrame或Series对象，使用DataFrame或Series对象的head()方法可以查看前n行数据。 1234567#导入相关的库import pandas as pdimport numpy as np#读取数据data = pd.read_csv(&#x27;./dataset/data.csv&#x27;)#查看数据data.head() 2.2 查看数据集的基本信息调用DataFrame对象的info()方法，获取数据的列名，非空值个数，列数据类型，内存占用信息。 1data.info() 数据集索引为0～599，共600条数据。各字段数据类型均为字符型。 3 数据清洗3.1 提取价格数值由于当前价格一列中含有¥符号，想对图书价格进行统计分析，需要从当前价格中取出价格的数值。借助正则表达书来完成上述操作。re库是python中正则表达式的支持库，使用findall()函数将当前价格中的数值提取出来，保存为新一列当前价格_match，findall()函数返回字符串中所有与正则表达式匹配的全部字符串，返回形式为数组。 +将前面的模式匹配一次或多次 ？匹配前一个字符零次或一次 *将前面的模式匹配零次或多次 .匹配除换行符之外的任意字符 \\转译字符 \\d匹配数字0～9 \\d{n}匹配正好n位数的数字 \\d{n,}匹配至少为n位的数字 \\d{n,m}匹配m～n位数的数字 [A-Za-z]+匹配英文字母组成的字符串 [A-Za-z0-9]+匹配由数字和英文字母组成的字符串DataFrame对象中apply方法可以将某个函数应用到由列或行形成的Series对象上，定义一个函数num_func，用于提取价格数值，然后使用apply方法将num_func应用到当前价格一列上。 1data[&#x27;当前价格&#x27;] 12345678import re#使用正则表达式将当前价格一列只读取数字部分并创建新的一列def func(data): result = re.findall(r&#x27;\\d+\\.?\\d*&#x27;,data) return float(result[0])data[&#x27;当前价格_match&#x27;] = data[&#x27;当前价格&#x27;].apply(func)data.head(3) 3.2 提取评论数值由于评论数一列中不仅包含数值，对评论数进行统计分析，需要从评论数一列中提取出评论的数值，保存为新的一列评论数_match。 1data[&#x27;评论数&#x27;] 12345678import re# 定义读取评论数的函数def func_1(data): esult = re.findall(r&#x27;\\d+&#x27;,data) return int(result[0])# 利用apply方法，将每一条数据进行处理data[&#x27;评论数_match&#x27;] = data[&#x27;评论数&#x27;].apply(func_1) 12# 查看是否处理成功data.head(3) 3.3 转换图书星级数值星级一列中同样包含一些其他字符，从星级一列中提取出星级的数值，将星级数值转换到[0,5]区间内，保存新的一列为星级_match。 123#提取星级数data[&#x27;星级_match&#x27;] = data[&#x27;星级&#x27;].apply(func_1)data.head(3) 12#将星级除以20，取值范围转换到[0,5]的区间内data[&#x27;星级_match_cal&#x27;] = data[&#x27;星级_match&#x27;].apply(lambda x:x/20) 1data.head(3) 3.4 提取作者、出版时间和出版社出版信息中包含作者、出版日期、出版社，用/分割为三部分，分三列存放，字符串对象的split方法通过制定分隔符对字符串进行切片。 1data[&#x27;出版信息&#x27;][:5] 1234# 将出版信息分割成三列，分别提取出作者、出版日期和出版社# 提取出作者data[&#x27;作者&#x27;] = data[&#x27;出版信息&#x27;].apply(lambda x:x.split(&#x27;/&#x27;)[0])data.head(3) 提取出的出版时间为字符串对象，我们可以通过datetime库中的strptime函数将字符串转换为datetime时间类型对象。 12345678910111213# 用正则表达式提取日期，并将日期字符串转换成日期格式from datetime import datetimedef func_2(data): result = re.findall(r&#x27;\\d&#123;4&#125;-\\d&#123;2&#125;-\\d&#123;2&#125;&#x27;,data) if len(result)&lt;1: return None else: return datetime.strptime(result[0],&#x27;%Y-%m-%d&#x27;) #返回日期类型# 提取日期，并添加为新的一列data[&#x27;出版日期&#x27;] = data[&#x27;出版信息&#x27;].apply(func_2)data.head(3) 12345# 提取出版社一列，并添加为新的一列data[&#x27;出版社&#x27;] = data[&#x27;出版信息&#x27;].apply(lambda x:x.split(&#x27;\\&#x27;)[-1])# 查看结果data.head(3) 3.5 提取书名和简介书名字段包含书名和书籍的相关介绍。以空格为分隔符对字段进行分割，提取图书的书名和简介部分。 1data[&#x27;书名&#x27;][:5] 123456#将&#x27;【】&#x27;和&#x27;[]&#x27;以及之间的内容，用空格来代替def func_3(data): data = data.strip()#先去除头和尾的空格 data = re.sub(&quot;【.*?】&quot;,&quot; &quot;,data) data = re.sub(&quot;\\[.*?\\]&quot;,&quot; &quot;,data) return data.split(&quot; &quot;) 12data[&#x27;书名_split&#x27;] = data[&#x27;书名&#x27;].apply(func_3)data[&#x27;书名_split&#x27;][:5] 123# 提取书名data[&#x27;书名_split_1&#x27;] = data[&#x27;书名_split&#x27;].apply(lambda x:x[0])data[&#x27;书名_split_1&#x27;][:5] 1234#因为分割后的字段长度不唯一，所以从第三个开始我们要先判定每个字段分割后的长度，之后再进行提取# 提取简介1data[&#x27;书名_split_2&#x27;] = data[&#x27;书名_split&#x27;].apply(lambda x: None if len(x)&lt;=1 else x[1])data[&#x27;书名_split_2&#x27;][:5] 123# 提取简介2data[&#x27;书名_split_3&#x27;] = data[&#x27;书名_split&#x27;].apply(lambda x: None if len(x)&lt;=2 else x[2])data[&#x27;书名_split_3&#x27;][:5] 1data.head(3) 3.6 删除不需要的列使用DataFrame对象的drop方法删除不需要的列。 123# 删除不需要的列data.drop([&#x27;书名&#x27;,&#x27;出版信息&#x27;,&#x27;当前价格&#x27;,&#x27;星级&#x27;,&#x27;评论数&#x27;,&#x27;星级_match&#x27;,&#x27;书名_split&#x27;],axis=1,implace=True)data.head(3) 3.7 修改列名使用DataFrame对象的rname对列进行重命名。 123# 修改列名data.rename(columns=&#123;&#x27;当前价格_match&#x27;:&#x27;当前价格&#x27;,&#x27;评论数_match&#x27;:&#x27;评论数&#x27;,&#x27;星级_match_cal&#x27;:&#x27;星级&#x27;,&#x27;书名_split_1&#x27;:&#x27;书名&#x27;,&#x27;书名_split_2&#x27;:&#x27;简介1&#x27;,&#x27;书名_split_3&#x27;:&#x27;简介2&#x27;&#125;,implace=True)data.head(3) 4 保存数据使用DataFrame对象的to_csv方法将处理好的数据保存为CSV文件。 1data.to_csv(&#x27;当当网机器学习图书数据(已清洗).csv&#x27;, sep=&#x27;,&#x27;,encoding=&#x27;utf8&#x27;,index=False)"},{"title":"Hello World","path":"/2023/08/06/hello-world/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment"}]